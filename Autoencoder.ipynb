{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualization library\n",
    "import matplotlib.pyplot as plt # visualization library\n",
    "from plotly.offline import init_notebook_mode, iplot # plotly offline mode\n",
    "import plotly.graph_objs as go # plotly graphical object\n",
    "\n",
    "\n",
    "import src.data.timeseries_eda as eda \n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "# ignore filters\n",
    "warnings.filterwarnings(\"ignore\") # if there is a warning after some codes, this will avoid us to see them.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'XAUUSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_bid</th>\n",
       "      <th>low_bid</th>\n",
       "      <th>high_bid</th>\n",
       "      <th>close_bid</th>\n",
       "      <th>volume_bid</th>\n",
       "      <th>open_ask</th>\n",
       "      <th>low_ask</th>\n",
       "      <th>high_ask</th>\n",
       "      <th>close_ask</th>\n",
       "      <th>volume_ask</th>\n",
       "      <th>avg_spread</th>\n",
       "      <th>tick_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1183.410034</td>\n",
       "      <td>1183.409058</td>\n",
       "      <td>1187.402954</td>\n",
       "      <td>1186.664062</td>\n",
       "      <td>0.54846</td>\n",
       "      <td>1185.050049</td>\n",
       "      <td>1184.531982</td>\n",
       "      <td>1187.847046</td>\n",
       "      <td>1187.108032</td>\n",
       "      <td>0.64480</td>\n",
       "      <td>0.511757</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1186.684082</td>\n",
       "      <td>1184.260986</td>\n",
       "      <td>1188.281982</td>\n",
       "      <td>1186.182007</td>\n",
       "      <td>2.10916</td>\n",
       "      <td>1187.119995</td>\n",
       "      <td>1184.578003</td>\n",
       "      <td>1188.621094</td>\n",
       "      <td>1186.478027</td>\n",
       "      <td>2.17188</td>\n",
       "      <td>0.325975</td>\n",
       "      <td>4428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1186.260986</td>\n",
       "      <td>1184.480957</td>\n",
       "      <td>1187.481079</td>\n",
       "      <td>1185.842041</td>\n",
       "      <td>3.02581</td>\n",
       "      <td>1186.568970</td>\n",
       "      <td>1184.788940</td>\n",
       "      <td>1187.761963</td>\n",
       "      <td>1186.141968</td>\n",
       "      <td>2.69611</td>\n",
       "      <td>0.299324</td>\n",
       "      <td>6195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1185.881104</td>\n",
       "      <td>1180.581055</td>\n",
       "      <td>1187.940918</td>\n",
       "      <td>1182.711060</td>\n",
       "      <td>7.58135</td>\n",
       "      <td>1186.141968</td>\n",
       "      <td>1180.890991</td>\n",
       "      <td>1188.302002</td>\n",
       "      <td>1182.980957</td>\n",
       "      <td>8.02604</td>\n",
       "      <td>0.277019</td>\n",
       "      <td>13557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1182.851074</td>\n",
       "      <td>1167.430054</td>\n",
       "      <td>1194.330933</td>\n",
       "      <td>1187.940918</td>\n",
       "      <td>16.77736</td>\n",
       "      <td>1182.980957</td>\n",
       "      <td>1167.908936</td>\n",
       "      <td>1194.708008</td>\n",
       "      <td>1188.234985</td>\n",
       "      <td>18.69664</td>\n",
       "      <td>0.277561</td>\n",
       "      <td>33036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_bid      low_bid     high_bid    close_bid  volume_bid  \\\n",
       "0  1183.410034  1183.409058  1187.402954  1186.664062     0.54846   \n",
       "1  1186.684082  1184.260986  1188.281982  1186.182007     2.10916   \n",
       "2  1186.260986  1184.480957  1187.481079  1185.842041     3.02581   \n",
       "3  1185.881104  1180.581055  1187.940918  1182.711060     7.58135   \n",
       "4  1182.851074  1167.430054  1194.330933  1187.940918    16.77736   \n",
       "\n",
       "      open_ask      low_ask     high_ask    close_ask  volume_ask  avg_spread  \\\n",
       "0  1185.050049  1184.531982  1187.847046  1187.108032     0.64480    0.511757   \n",
       "1  1187.119995  1184.578003  1188.621094  1186.478027     2.17188    0.325975   \n",
       "2  1186.568970  1184.788940  1187.761963  1186.141968     2.69611    0.299324   \n",
       "3  1186.141968  1180.890991  1188.302002  1182.980957     8.02604    0.277019   \n",
       "4  1182.980957  1167.908936  1194.708008  1188.234985    18.69664    0.277561   \n",
       "\n",
       "   tick_number  \n",
       "0         1476  \n",
       "1         4428  \n",
       "2         6195  \n",
       "3        13557  \n",
       "4        33036  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_data = pd.read_csv(f'data/{symbol}_4h.csv')\n",
    "market_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for col in market_data.columns:\n",
    "    features.append(col)\n",
    "feature = features[:-1]\n",
    "target = features[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataloader import CreateDataset\n",
    "my_dataset = CreateDataset(market_data, 10, feature, target)\n",
    "\n",
    "train_num = int(len(market_data)*0.8)\n",
    "train_data = market_data[:train_num].dropna()\n",
    "test_data = market_data[train_num:].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_bid</th>\n",
       "      <th>low_bid</th>\n",
       "      <th>high_bid</th>\n",
       "      <th>close_bid</th>\n",
       "      <th>volume_bid</th>\n",
       "      <th>open_ask</th>\n",
       "      <th>low_ask</th>\n",
       "      <th>high_ask</th>\n",
       "      <th>close_ask</th>\n",
       "      <th>volume_ask</th>\n",
       "      <th>avg_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10796</th>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10797</th>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10798</th>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13491</th>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13493</th>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>0.008853</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open_bid   low_bid  high_bid  close_bid  volume_bid  open_ask  \\\n",
       "10796  0.008226  0.008213  0.008230   0.008223    0.000023  0.008227   \n",
       "10797  0.008223  0.008216  0.008224   0.008217    0.000005  0.008224   \n",
       "10798  0.008217  0.008206  0.008221   0.008216    0.000020  0.008218   \n",
       "10799  0.008216  0.008198  0.008219   0.008209    0.000029  0.008217   \n",
       "10800  0.008209  0.008195  0.008215   0.008209    0.000028  0.008210   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "13491  0.008876  0.008869  0.008916   0.008911    0.000021  0.008878   \n",
       "13492  0.008911  0.008888  0.008914   0.008890    0.000028  0.008913   \n",
       "13493  0.008890  0.008832  0.008901   0.008853    0.000050  0.008892   \n",
       "13494  0.008853  0.008850  0.008872   0.008871    0.000025  0.008855   \n",
       "13495  0.008871  0.008861  0.008872   0.008864    0.000001  0.008873   \n",
       "\n",
       "        low_ask  high_ask  close_ask  volume_ask  avg_spread  \n",
       "10796  0.008214  0.008231   0.008224    0.000020    0.000001  \n",
       "10797  0.008217  0.008226   0.008218    0.000005    0.000001  \n",
       "10798  0.008207  0.008222   0.008217    0.000020    0.000001  \n",
       "10799  0.008199  0.008221   0.008210    0.000025    0.000001  \n",
       "10800  0.008196  0.008216   0.008211    0.000023    0.000001  \n",
       "...         ...       ...        ...         ...         ...  \n",
       "13491  0.008871  0.008918   0.008913    0.000021    0.000002  \n",
       "13492  0.008889  0.008916   0.008891    0.000014    0.000002  \n",
       "13493  0.008833  0.008902   0.008855    0.000053    0.000002  \n",
       "13494  0.008852  0.008873   0.008873    0.000016    0.000002  \n",
       "13495  0.008868  0.008873   0.008871    0.000001    0.000002  \n",
       "\n",
       "[2700 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.feature_engineering import PercentageFeatureAdder, BollingerBandAdder, TargetAdder, Scalar\n",
    "scalar = Scalar()\n",
    "train_data = scalar.fit_transform(train_data)\n",
    "test_data = scalar.fit_transform(test_data)\n",
    "\n",
    "train_data_x = train_data[feature]\n",
    "train_data_y = train_data[target]\n",
    "\n",
    "test_data_x = test_data[feature]\n",
    "test_data_y = test_data[target]\n",
    "test_data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_bid</th>\n",
       "      <th>low_bid</th>\n",
       "      <th>high_bid</th>\n",
       "      <th>close_bid</th>\n",
       "      <th>volume_bid</th>\n",
       "      <th>open_ask</th>\n",
       "      <th>low_ask</th>\n",
       "      <th>high_ask</th>\n",
       "      <th>close_ask</th>\n",
       "      <th>volume_ask</th>\n",
       "      <th>avg_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570064</td>\n",
       "      <td>0.570063</td>\n",
       "      <td>0.571987</td>\n",
       "      <td>0.571631</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.570854</td>\n",
       "      <td>0.570604</td>\n",
       "      <td>0.572201</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571641</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.572411</td>\n",
       "      <td>0.571399</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.571851</td>\n",
       "      <td>0.570627</td>\n",
       "      <td>0.572574</td>\n",
       "      <td>0.571542</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571437</td>\n",
       "      <td>0.570580</td>\n",
       "      <td>0.572025</td>\n",
       "      <td>0.571235</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.571586</td>\n",
       "      <td>0.570728</td>\n",
       "      <td>0.572160</td>\n",
       "      <td>0.571380</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571254</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>0.572247</td>\n",
       "      <td>0.569727</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.571380</td>\n",
       "      <td>0.568850</td>\n",
       "      <td>0.572420</td>\n",
       "      <td>0.569857</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569795</td>\n",
       "      <td>0.562366</td>\n",
       "      <td>0.575325</td>\n",
       "      <td>0.572247</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.569857</td>\n",
       "      <td>0.562597</td>\n",
       "      <td>0.575506</td>\n",
       "      <td>0.572388</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13491</th>\n",
       "      <td>0.938567</td>\n",
       "      <td>0.937840</td>\n",
       "      <td>0.942816</td>\n",
       "      <td>0.942300</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.938726</td>\n",
       "      <td>0.937994</td>\n",
       "      <td>0.942980</td>\n",
       "      <td>0.942445</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13492</th>\n",
       "      <td>0.942291</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>0.942556</td>\n",
       "      <td>0.940012</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.942435</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.942744</td>\n",
       "      <td>0.940181</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13493</th>\n",
       "      <td>0.940012</td>\n",
       "      <td>0.933890</td>\n",
       "      <td>0.941173</td>\n",
       "      <td>0.936168</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.940200</td>\n",
       "      <td>0.934049</td>\n",
       "      <td>0.941267</td>\n",
       "      <td>0.936331</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>0.938058</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.936331</td>\n",
       "      <td>0.935979</td>\n",
       "      <td>0.938283</td>\n",
       "      <td>0.938206</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>0.938037</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.938106</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.938206</td>\n",
       "      <td>0.937756</td>\n",
       "      <td>0.938273</td>\n",
       "      <td>0.938041</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13496 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open_bid   low_bid  high_bid  close_bid  volume_bid  open_ask  \\\n",
       "0      0.570064  0.570063  0.571987   0.571631    0.000264  0.570854   \n",
       "1      0.571641  0.570474  0.572411   0.571399    0.001016  0.571851   \n",
       "2      0.571437  0.570580  0.572025   0.571235    0.001458  0.571586   \n",
       "3      0.571254  0.568701  0.572247   0.569727    0.003652  0.571380   \n",
       "4      0.569795  0.562366  0.575325   0.572247    0.008082  0.569857   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "13491  0.938567  0.937840  0.942816   0.942300    0.002172  0.938726   \n",
       "13492  0.942291  0.939800  0.942556   0.940012    0.002990  0.942435   \n",
       "13493  0.940012  0.933890  0.941173   0.936168    0.005331  0.940200   \n",
       "13494  0.936154  0.935826  0.938130   0.938058    0.002644  0.936331   \n",
       "13495  0.938037  0.937017  0.938106   0.937276    0.000146  0.938206   \n",
       "\n",
       "        low_ask  high_ask  close_ask  volume_ask  avg_spread  \n",
       "0      0.570604  0.572201   0.571845    0.000311    0.000247  \n",
       "1      0.570627  0.572574   0.571542    0.001046    0.000157  \n",
       "2      0.570728  0.572160   0.571380    0.001299    0.000144  \n",
       "3      0.568850  0.572420   0.569857    0.003866    0.000133  \n",
       "4      0.562597  0.575506   0.572388    0.009006    0.000134  \n",
       "...         ...       ...        ...         ...         ...  \n",
       "13491  0.937994  0.942980   0.942445    0.002191    0.000163  \n",
       "13492  0.939948  0.942744   0.940181    0.001445    0.000161  \n",
       "13493  0.934049  0.941267   0.936331    0.005575    0.000162  \n",
       "13494  0.935979  0.938283   0.938206    0.001729    0.000163  \n",
       "13495  0.937756  0.938273   0.938041    0.000121    0.000229  \n",
       "\n",
       "[13496 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_full_data = market_data[feature]\n",
    "a_full_data = scalar.fit_transform(a_full_data)\n",
    "a_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shuffled\n",
      "Epoch 1/10 | Step 0/210 | train loss: 407.8046 | l1 loss: 406.6402 | sparsity loss: 5.8223\n",
      "Epoch 1/10 | Step 50/210 | train loss: 212.9365 | l1 loss: 211.7696 | sparsity loss: 5.8347\n",
      "Epoch 1/10 | Step 100/210 | train loss: 113.6182 | l1 loss: 112.3273 | sparsity loss: 6.4547\n",
      "Epoch 1/10 | Step 150/210 | train loss: 53.9224 | l1 loss: 52.5102 | sparsity loss: 7.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Step 200/210 | train loss: 58.4599 | l1 loss: 56.9887 | sparsity loss: 7.3559\n",
      "Data Shuffled\n",
      "Epoch 2/10 | Step 0/210 | train loss: 64.8776 | l1 loss: 63.3913 | sparsity loss: 7.4313\n",
      "Epoch 2/10 | Step 50/210 | train loss: 61.4929 | l1 loss: 59.9921 | sparsity loss: 7.5042\n",
      "Epoch 2/10 | Step 100/210 | train loss: 59.0791 | l1 loss: 57.5309 | sparsity loss: 7.7410\n",
      "Epoch 2/10 | Step 150/210 | train loss: 51.7273 | l1 loss: 50.1583 | sparsity loss: 7.8447\n",
      "Epoch 2/10 | Step 200/210 | train loss: 48.6230 | l1 loss: 47.0428 | sparsity loss: 7.9013\n",
      "Data Shuffled\n",
      "Epoch 3/10 | Step 0/210 | train loss: 56.3139 | l1 loss: 54.6707 | sparsity loss: 8.2158\n",
      "Epoch 3/10 | Step 50/210 | train loss: 44.3552 | l1 loss: 42.7505 | sparsity loss: 8.0236\n",
      "Epoch 3/10 | Step 100/210 | train loss: 51.1173 | l1 loss: 49.4739 | sparsity loss: 8.2174\n",
      "Epoch 3/10 | Step 150/210 | train loss: 45.5854 | l1 loss: 43.9398 | sparsity loss: 8.2280\n",
      "Epoch 3/10 | Step 200/210 | train loss: 45.8264 | l1 loss: 44.1560 | sparsity loss: 8.3518\n",
      "Data Shuffled\n",
      "Epoch 4/10 | Step 0/210 | train loss: 54.5303 | l1 loss: 52.8197 | sparsity loss: 8.5531\n",
      "Epoch 4/10 | Step 50/210 | train loss: 44.9170 | l1 loss: 43.2426 | sparsity loss: 8.3723\n",
      "Epoch 4/10 | Step 100/210 | train loss: 43.5218 | l1 loss: 41.8467 | sparsity loss: 8.3753\n",
      "Epoch 4/10 | Step 150/210 | train loss: 46.8055 | l1 loss: 45.1135 | sparsity loss: 8.4600\n",
      "Epoch 4/10 | Step 200/210 | train loss: 32.8481 | l1 loss: 31.2001 | sparsity loss: 8.2403\n",
      "Data Shuffled\n",
      "Epoch 5/10 | Step 0/210 | train loss: 44.3489 | l1 loss: 42.6625 | sparsity loss: 8.4322\n",
      "Epoch 5/10 | Step 50/210 | train loss: 42.0038 | l1 loss: 40.3293 | sparsity loss: 8.3725\n",
      "Epoch 5/10 | Step 100/210 | train loss: 37.2432 | l1 loss: 35.5973 | sparsity loss: 8.2293\n",
      "Epoch 5/10 | Step 150/210 | train loss: 36.4442 | l1 loss: 34.7688 | sparsity loss: 8.3771\n",
      "Epoch 5/10 | Step 200/210 | train loss: 41.9530 | l1 loss: 40.2487 | sparsity loss: 8.5213\n",
      "Data Shuffled\n",
      "Epoch 6/10 | Step 0/210 | train loss: 30.9960 | l1 loss: 29.3714 | sparsity loss: 8.1230\n",
      "Epoch 6/10 | Step 50/210 | train loss: 31.5981 | l1 loss: 29.9352 | sparsity loss: 8.3148\n",
      "Epoch 6/10 | Step 100/210 | train loss: 28.0486 | l1 loss: 26.4006 | sparsity loss: 8.2398\n",
      "Epoch 6/10 | Step 150/210 | train loss: 27.7754 | l1 loss: 26.1205 | sparsity loss: 8.2741\n",
      "Epoch 6/10 | Step 200/210 | train loss: 23.8858 | l1 loss: 22.2256 | sparsity loss: 8.3012\n",
      "Data Shuffled\n",
      "Epoch 7/10 | Step 0/210 | train loss: 23.0941 | l1 loss: 21.4511 | sparsity loss: 8.2151\n",
      "Epoch 7/10 | Step 50/210 | train loss: 20.9590 | l1 loss: 19.3449 | sparsity loss: 8.0707\n",
      "Epoch 7/10 | Step 100/210 | train loss: 21.7934 | l1 loss: 20.1347 | sparsity loss: 8.2936\n",
      "Epoch 7/10 | Step 150/210 | train loss: 15.4582 | l1 loss: 13.8685 | sparsity loss: 7.9486\n",
      "Epoch 7/10 | Step 200/210 | train loss: 14.5259 | l1 loss: 12.9228 | sparsity loss: 8.0155\n",
      "Data Shuffled\n",
      "Epoch 8/10 | Step 0/210 | train loss: 14.4302 | l1 loss: 12.8374 | sparsity loss: 7.9643\n",
      "Epoch 8/10 | Step 50/210 | train loss: 9.8589 | l1 loss: 8.3148 | sparsity loss: 7.7202\n",
      "Epoch 8/10 | Step 100/210 | train loss: 7.6899 | l1 loss: 6.1344 | sparsity loss: 7.7772\n",
      "Epoch 8/10 | Step 150/210 | train loss: 5.9686 | l1 loss: 4.4159 | sparsity loss: 7.7633\n",
      "Epoch 8/10 | Step 200/210 | train loss: 4.4838 | l1 loss: 2.9729 | sparsity loss: 7.5545\n",
      "Data Shuffled\n",
      "Epoch 9/10 | Step 0/210 | train loss: 4.7692 | l1 loss: 3.2382 | sparsity loss: 7.6548\n",
      "Epoch 9/10 | Step 50/210 | train loss: 4.0790 | l1 loss: 2.5758 | sparsity loss: 7.5158\n",
      "Epoch 9/10 | Step 100/210 | train loss: 3.8070 | l1 loss: 2.3347 | sparsity loss: 7.3612\n",
      "Epoch 9/10 | Step 150/210 | train loss: 3.2013 | l1 loss: 1.7450 | sparsity loss: 7.2816\n",
      "Epoch 9/10 | Step 200/210 | train loss: 3.8867 | l1 loss: 2.4231 | sparsity loss: 7.3179\n",
      "Data Shuffled\n",
      "Epoch 10/10 | Step 0/210 | train loss: 4.0446 | l1 loss: 2.5349 | sparsity loss: 7.5481\n",
      "Epoch 10/10 | Step 50/210 | train loss: 3.7062 | l1 loss: 2.2405 | sparsity loss: 7.3282\n",
      "Epoch 10/10 | Step 100/210 | train loss: 3.5017 | l1 loss: 2.0885 | sparsity loss: 7.0661\n",
      "Epoch 10/10 | Step 150/210 | train loss: 3.8136 | l1 loss: 2.3633 | sparsity loss: 7.2514\n",
      "Epoch 10/10 | Step 200/210 | train loss: 3.1398 | l1 loss: 1.7745 | sparsity loss: 6.8261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.models.autoencoder import Autoencoder\n",
    "a_full_data_array = a_full_data.values\n",
    "autoencoder = Autoencoder(11)\n",
    "autoencoder.fit(X = a_full_data_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
